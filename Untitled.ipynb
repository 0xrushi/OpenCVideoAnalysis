{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f175c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "image = face_recognition.load_image_file(\"1.png\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d3a986d-0b10-44b0-a07a-4743e7ff3b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_image = face_recognition.load_image_file(\"1.png\")\n",
    "unknown_image = face_recognition.load_image_file(\"3.png\")\n",
    "\n",
    "biden_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "473a8615-d51b-4020-82c5-a7f67ae22b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognition.face_encodings(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bedf965d-b753-42d5-ab24-bba2f51972fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 68, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d81a162-2b8a-4742-8379-72254c9ff04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 62, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bbd4206-3fc9-43a8-b3ae-f8ba25c8a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 62, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7eb7bb5-787c-44b2-bc55-e8b9683d7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "pp = np.asarray(Image.fromarray(face_recognition.load_image_file(\"3.png\")).resize((280,400), Image.ANTIALIAS))\n",
    "Image.fromarray(pp).save('53.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98671f88-fc2d-437e-8b1b-24a99dcd3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\n",
      "  Downloading deepface-0.0.74-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m911.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gdown>=3.10.1\n",
      "  Using cached gdown-4.4.0-py3-none-any.whl\n",
      "Collecting retina-face>=0.0.1\n",
      "  Using cached retina_face-0.0.10-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./python38venv/lib/python3.8/site-packages (from deepface) (1.20.3)\n",
      "Collecting Flask>=1.1.2\n",
      "  Using cached Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in ./python38venv/lib/python3.8/site-packages (from deepface) (4.62.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in ./python38venv/lib/python3.8/site-packages (from deepface) (1.3.4)\n",
      "Collecting mtcnn>=0.1.0\n",
      "  Using cached mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Collecting tensorflow>=1.9.0\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=5.2.0 in ./python38venv/lib/python3.8/site-packages (from deepface) (9.0.0)\n",
      "Collecting keras>=2.2.0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: opencv-python>=3.4.4 in ./python38venv/lib/python3.8/site-packages (from deepface) (4.5.3.56)\n",
      "Requirement already satisfied: click>=7.1.2 in ./python38venv/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (8.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./python38venv/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (3.1.1)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six in ./python38venv/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in ./python38venv/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./python38venv/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (4.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./python38venv/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./python38venv/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./python38venv/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.19.4)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in ./python38venv/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (4.1.1)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: setuptools in ./python38venv/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (60.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./python38venv/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./python38venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.37.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./python38venv/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 KB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./python38venv/lib/python3.8/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./python38venv/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./python38venv/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./python38venv/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./python38venv/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.9)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./python38venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->deepface) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, Werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, rsa, PySocks, pyasn1-modules, opt-einsum, oauthlib, keras-preprocessing, itsdangerous, importlib-metadata, h5py, grpcio, google-pasta, gast, filelock, cachetools, astunparse, absl-py, requests-oauthlib, mtcnn, markdown, google-auth, Flask, google-auth-oauthlib, gdown, tensorboard, tensorflow, retina-face, deepface\n",
      "Successfully installed Flask-2.0.3 PySocks-1.7.1 Werkzeug-2.0.3 absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 deepface-0.0.74 filelock-3.6.0 flatbuffers-2.0 gast-0.5.3 gdown-4.4.0 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 importlib-metadata-4.11.3 itsdangerous-2.1.2 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 mtcnn-0.1.1 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 retina-face-0.0.10 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109 wrapt-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a20120-7e4b-4f1d-8328-5b92e2f397a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet512\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenFace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepFace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArcFace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDlib\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# result = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", model_name = models[1])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m53.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m54.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m result\n",
      "File \u001b[0;32m/mnt/hdd2/gender_detect/python38venv/lib/python3.8/site-packages/deepface/DeepFace.py:161\u001b[0m, in \u001b[0;36mverify\u001b[0;34m(img1_path, img2_path, model_name, distance_metric, model, enforce_detection, detector_backend, align, prog_bar, normalization)\u001b[0m\n\u001b[1;32m    158\u001b[0m custom_model \u001b[38;5;241m=\u001b[39m models[i]\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m#img_path, model_name = 'VGG-Face', model = None, enforce_detection = True, detector_backend = 'mtcnn'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m img1_representation \u001b[38;5;241m=\u001b[39m \u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg1_path\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcustom_model\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m img2_representation \u001b[38;5;241m=\u001b[39m represent(img_path \u001b[38;5;241m=\u001b[39m img2_path\n\u001b[1;32m    169\u001b[0m \t\t, model_name \u001b[38;5;241m=\u001b[39m model_name, model \u001b[38;5;241m=\u001b[39m custom_model\n\u001b[1;32m    170\u001b[0m \t\t, enforce_detection \u001b[38;5;241m=\u001b[39m enforce_detection, detector_backend \u001b[38;5;241m=\u001b[39m detector_backend\n\u001b[1;32m    171\u001b[0m \t\t, align \u001b[38;5;241m=\u001b[39m align\n\u001b[1;32m    172\u001b[0m \t\t, normalization \u001b[38;5;241m=\u001b[39m normalization\n\u001b[1;32m    173\u001b[0m \t\t)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m#----------------------\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#find distances between embeddings\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/hdd2/gender_detect/python38venv/lib/python3.8/site-packages/deepface/DeepFace.py:752\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, model, enforce_detection, detector_backend, align, normalization)\u001b[0m\n\u001b[1;32m    749\u001b[0m input_shape_x, input_shape_y \u001b[38;5;241m=\u001b[39m functions\u001b[38;5;241m.\u001b[39mfind_input_shape(model)\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m#detect and align\u001b[39;00m\n\u001b[0;32m--> 752\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_shape_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m#---------------------------------\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m#custom normalization\u001b[39;00m\n\u001b[1;32m    761\u001b[0m img \u001b[38;5;241m=\u001b[39m functions\u001b[38;5;241m.\u001b[39mnormalize_input(img \u001b[38;5;241m=\u001b[39m img, normalization \u001b[38;5;241m=\u001b[39m normalization)\n",
      "File \u001b[0;32m/mnt/hdd2/gender_detect/python38venv/lib/python3.8/site-packages/deepface/commons/functions.py:178\u001b[0m, in \u001b[0;36mpreprocess_face\u001b[0;34m(img, target_size, grayscale, enforce_detection, detector_backend, return_region, align)\u001b[0m\n\u001b[1;32m    175\u001b[0m img \u001b[38;5;241m=\u001b[39m load_image(img)\n\u001b[1;32m    176\u001b[0m base_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 178\u001b[0m img, region \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m#--------------------------\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/mnt/hdd2/gender_detect/python38venv/lib/python3.8/site-packages/deepface/commons/functions.py:124\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(img, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[1;32m    122\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m img, img_region\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False."
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "# result = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", model_name = models[1])\n",
    "result = DeepFace.verify(img1_path = \"53.png\", img2_path = \"54.png\", model_name = models[7])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30d027f7-d4bf-4498-b14e-d1dc5cb70fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.png  2.png  3.png  4.png  5.png\n"
     ]
    }
   ],
   "source": [
    "!ls *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8d4fb-04f6-4078-b72f-485ff5164f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23226491-b953-4bed-886c-205eaba22309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
